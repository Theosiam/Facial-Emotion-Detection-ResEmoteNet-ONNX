{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model has been successfully exported to /home/theosiam/Repos/Autotrust/Autotrust/Facial_Expression_Recognition/ResEmoteNet.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from approach.ResEmoteNet import ResEmoteNet\n",
    "\n",
    "# Select the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the trained model\n",
    "model = ResEmoteNet().to(device)\n",
    "checkpoint = torch.load('./Weights/fer_model.pth', map_location=device) # YOU HAVE TO DOWNLOAD AND PUT THE WEIGHT FILE OF THE FER MODEL HERE\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Define a dummy input for ONNX export\n",
    "dummy_input = torch.randn(1, 3, 64, 64, device=device)  # Batch size 1, 3 color channels, 64x64 resolution\n",
    "\n",
    "# Specify the output ONNX file path\n",
    "onnx_file_path = \"ResEmoteNet.onnx\"\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(\n",
    "    model,                        # Model to export\n",
    "    dummy_input,                  # Dummy input for tracing\n",
    "    onnx_file_path,               # Path to save the ONNX file\n",
    "    export_params=True,           # Store trained parameter weights inside the model\n",
    "    opset_version=11,             # ONNX version to export to\n",
    "    do_constant_folding=True,     # Optimize the model by folding constant nodes\n",
    "    input_names=['input'],        # Name of the input tensor\n",
    "    output_names=['output'],      # Name of the output tensor\n",
    "    dynamic_axes={                # Allow for variable input sizes\n",
    "        'input': {0: 'batch_size'},  # Dynamic batch size\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model has been successfully exported to {onnx_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dddsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
